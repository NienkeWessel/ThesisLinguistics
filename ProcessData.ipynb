{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import unittest\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tolerance formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolerance_formula(N, e):\n",
    "    '''\n",
    "    Tolerance formula from Yang, p. 9\n",
    "    '''\n",
    "    print(N, e)\n",
    "    return e <= N/np.log(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data file operations\n",
    "This part of the code deals with file operations, such as reading and closing files\n",
    "\n",
    "## Preferably use the final function!\n",
    "Older ones are kind of deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(filename, df):\n",
    "    \"\"\"\n",
    "    Code from: https://www.kite.com/python/answers/how-to-save-a-pandas-dataframe-in-python\n",
    "    \"\"\"\n",
    "    df.to_pickle(filename)\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Code from: https://www.kite.com/python/answers/how-to-save-a-pandas-dataframe-in-python\n",
    "    \"\"\"\n",
    "    return pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_representation_to_dataframe(df):\n",
    "    '''\n",
    "    Appends the syllable representations of the model and realization to the dataframe \n",
    "    to have all information in one place\n",
    "    \n",
    "    df: data set, of which the representations need to be appended\n",
    "    \n",
    "    No return, as it mutates the df object\n",
    "    '''\n",
    "    df['rep_model'] = df.model.apply(build_syllable_representation)\n",
    "    df['rep_realization'] = df.realization.apply(build_syllable_representation)\n",
    "    #print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nonmatches_to_csv(filename, df, comparison, header = ['Name', 'Age', 'word', 'model','realization','stressmodel','stressrealization'], apply_filter=True):\n",
    "    with open(filename, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write the header\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # write the data\n",
    "        for n, a, word, w,v in collect_nonmatches_metadata(df, comparison):\n",
    "            if not apply_filter:\n",
    "                writer.writerow([n,a,word,w, v, build_syllable_representation(w), build_syllable_representation(v)])\n",
    "            else:\n",
    "                rep_w = build_syllable_representation(w)\n",
    "                rep_v = build_syllable_representation(v)\n",
    "                # If at least one of the two representations has 2 or more syllables, then we are interested\n",
    "                if len(rep_w) >= 2 or len(rep_v) >= 2: \n",
    "                    writer.writerow([n,a,word,w, v, rep_w, rep_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stats_to_csv(filename, a,b,c,d,e):\n",
    "    '''\n",
    "    stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act\n",
    "    '''\n",
    "    with open(filename, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write the header\n",
    "        writer.writerow(['number','modellengthall','realizationlengthall','lengthmatch', 'modellengthnonmatch', 'realizationlengthnonmatch'])\n",
    "\n",
    "        # write the data\n",
    "        for i in range(10):\n",
    "            writer.writerow([i, a[i], b[i], c[i], d[i], e[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_csv(filename, df):\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, written, model, realization, rep_model, rep_realization):\n",
    "        self.written = written\n",
    "        self.model = model\n",
    "        self.realization = realization\n",
    "        self.rep_model = rep_model\n",
    "        self.rep_realization = rep_realization\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.written == other.written\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.written.__hash__()\n",
    "\n",
    "    def is_bisyl(self):\n",
    "        return len(self.rep_model) == 2\n",
    "    \n",
    "    def is_iambic_bisyl(self):\n",
    "        if len(self.rep_model) == 2:\n",
    "            return self.rep_model[1]\n",
    "        else:\n",
    "            return False \n",
    "    \n",
    "    def is_final_syllable_heavy(self):\n",
    "        if self.model[-1] in ipa_vowels:\n",
    "            # if the last letter is a vowel, we only have a heavy syllable if it is a diphtong, so if the letter before it is also a vowel\n",
    "            return self.model[-2] in ipa_vowels\n",
    "        else: #so final letter in agnostic_symbols or consonants\n",
    "            return True\n",
    "    \n",
    "    def matches_pattern(self, pattern):\n",
    "        '''\n",
    "        Calculates whether the word matches the stress pattern\n",
    "        \n",
    "        pattern: string of F(alse) and T(rue) or A(gnostic) indicating the stress placement\n",
    "        Agnostic (or any other symbol) can be used to indicate that one does not care about the stress placement\n",
    "        \n",
    "        return: \n",
    "        '''\n",
    "        \n",
    "        # Initial check for length match. If not equal, no point in persuing (and prevents out of bound errors later on)\n",
    "        if len(pattern) != len(self.rep_model):\n",
    "            return False\n",
    "        \n",
    "        for i,c in enumerate(pattern):\n",
    "            if c == 'T':\n",
    "                if not self.rep_model[i]:\n",
    "                    return False\n",
    "            if c == 'F':\n",
    "                if self.rep_model[i]:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordlist class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordList:\n",
    "    \n",
    "    def __init__(self, time ):\n",
    "        '''\n",
    "        time: the point in time to which this wordlist refers\n",
    "        '''\n",
    "        self.time = time\n",
    "        self.wordlist = set()\n",
    "        \n",
    "    def __cmp__(self, other):\n",
    "        return cmp(self.time, other.time)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"%s\" % (self.time)\n",
    "    \n",
    "    \n",
    "    def add_word(self, word):\n",
    "        self.wordlist.add(word)\n",
    "\n",
    "    def add_prev_state_wordlist(prev_wordlist):\n",
    "        for word in prev_wordlist.wordlist:\n",
    "            self.wordlist.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child development class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChildDevelopment:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        name: child's name (just for bookkeeping purposes)\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.wordlists = []\n",
    "    \n",
    "    \n",
    "    def add_wordlist(self, wordlist):\n",
    "        '''\n",
    "        Appends wordlist to the wordlists of the child\n",
    "        \n",
    "        wordlist: the wordlist to be added\n",
    "        '''\n",
    "        self.wordlists.append(wordlist)\n",
    "    \n",
    "\n",
    "    def calculate_total_vocab_dev(self):\n",
    "        '''\n",
    "        Calculates the development of the vocabulary size, i.e. how the vocabulary grows through time\n",
    "        \n",
    "        returns: list of cumulative vocabulary sizes\n",
    "        \n",
    "        Todo: Add something similar for the dates so that we have those\n",
    "        '''\n",
    "        print(self.wordlists[0])\n",
    "        development = []\n",
    "        total_wordlist = set()\n",
    "        for wordlist in self.wordlists:\n",
    "            \n",
    "            for word in wordlist.wordlist:\n",
    "                total_wordlist.add(word)\n",
    "            development.append(len(total_wordlist))\n",
    "        return development\n",
    "\n",
    "    \n",
    "    def calculate_development_by_patterns(self, patterns):\n",
    "        '''\n",
    "        Calculates the wordlists for a list of patterns and the total development\n",
    "        For efficiency, this is done at once (building wordlists is expensive)\n",
    "        \n",
    "        patterns: the patterns one wants the developments of\n",
    "        return: list of developments for the patterns\n",
    "        '''\n",
    "        developments_counts = {}\n",
    "        developments = {}\n",
    "        \n",
    "        for p in patterns:\n",
    "            developments[p] = set()\n",
    "            developments_counts[p] = []\n",
    "        \n",
    "        \n",
    "        for wordlist in self.wordlists:\n",
    "            \n",
    "            for word in wordlist.wordlist:\n",
    "                for p in patterns:\n",
    "                    if word.matches_pattern(p):\n",
    "                        developments[p].add(word)\n",
    "            for p in patterns:\n",
    "                developments_counts[p].append(len(developments[p]))\n",
    "        \n",
    "        return developments_counts, developments\n",
    "        \n",
    "    \n",
    "    def determine_tolerance(self, total, exceptions):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        tolerance = []\n",
    "        for i in range(len(total)):\n",
    "            tolerance.append(tolerance_formula(total[i], exceptions[i]))\n",
    "        print(tolerance)\n",
    "        \n",
    "    \n",
    "    def plot_vocab_dev_bisyl(self):\n",
    "        development_bisyl, development_bisyl_iamb = self.calculate_bisyl_vocab_dev()\n",
    "        total_dev = self.calculate_total_vocab_dev()\n",
    "        \n",
    "        self.determine_tolerance(development_bisyl, development_bisyl_iamb)\n",
    "        \n",
    "        plt.plot(total_dev, label='Total vocabulary')\n",
    "        plt.plot(development_bisyl, label='Bisyllabic words')\n",
    "        plt.plot(development_bisyl_iamb, label='Bisyllabic iambic words')\n",
    "        plt.title('Development of ' + self.name)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def plot_vocab_dev(self, patterns):\n",
    "        developments_counts, developments = self.calculate_development_by_patterns(patterns)\n",
    "        total_dev = self.calculate_total_vocab_dev()\n",
    "        \n",
    "        #self.determine_tolerance(development_bisyl, development_bisyl_iamb)\n",
    "        \n",
    "        plt.plot(total_dev, label='Total vocabulary')\n",
    "        for p in patterns:\n",
    "            plt.plot(developments_counts[p], label=p)\n",
    "        plt.title('Development of ' + self.name)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wordlists_for_child(name, df):\n",
    "    '''\n",
    "    builds the child development object and fills it with word lists through time\n",
    "    Assumes df is not shuffled (i.e. that the words from the same time point are next to each other)\n",
    "    \n",
    "    name: child name\n",
    "    df: complete dataframe\n",
    "    returns: child development object\n",
    "    \n",
    "    TODO: Maybe move to __init__ of child\n",
    "    '''\n",
    "    df_child = df[df['Name'] == name]\n",
    "    print(df_child)\n",
    "    prev_time = 'P1Y10M28DT0H0M0S'\n",
    "    child_dev = ChildDevelopment(name)\n",
    "    wordlist = WordList('P1Y10M28DT0H0M0S')\n",
    "    for index, data_point in df_child.iterrows(): # Might be slow, see https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "        #print(data_point)\n",
    "        time = data_point['Age']\n",
    "        if prev_time != time: \n",
    "            child_dev.add_wordlist(wordlist)\n",
    "            wordlist = WordList(time)\n",
    "        \n",
    "        word = Word(data_point['word'], data_point['model'], data_point['realization'], data_point['rep_model'], data_point['rep_realization'])\n",
    "        wordlist.add_word(word)\n",
    "        \n",
    "        prev_time = time\n",
    "    return(child_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_vowels = ['a', 'ɑ', 'œ', 'æ', 'y', 'o', 'ɑ̈', 'i', 'u', 'ɪ', 'ə', 'ɛ', 'e', 'ɔ', 'ʌ', 'ø̈', 'ɛ̝','ʉ', 'œ̞', 'œ', 'ɛ̞', 'ʔ', 'ɒ','ø', 'æ̝', 'ə̆', 'o͡', 'o̝', 'ʊ', 'ɯ']#, '͡'] \n",
    "agnostic_symbols = ['͡', 'ː', 'ˑ'] # symbols that can either be a vowel or consonant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_syllable_representation(word, secondary=False):\n",
    "    \"\"\"\n",
    "    word: the word of which you want the syllable representation\n",
    "    \n",
    "    Returns the representation of the syllable in the form of a list of booleans, where true represents stressed and false unstressed\n",
    "    \"\"\"\n",
    "    if not isinstance(word, str):\n",
    "        return []\n",
    "    \n",
    "    representation = []\n",
    "    stressed = False\n",
    "    vowels = False\n",
    "    for c in list(word):\n",
    "        #print(c)\n",
    "        if secondary and (c == \"ˈ\" or c == \"ˌ\"):\n",
    "            stressed = True\n",
    "        elif not secondary and c == \"ˈ\":\n",
    "            stressed = True\n",
    "        elif c in ipa_vowels:\n",
    "            if not vowels:\n",
    "                vowels = True\n",
    "                representation.append(stressed)\n",
    "                stressed = False\n",
    "        elif c not in agnostic_symbols: #if we do not know whether something is a vowel or consonant, we leave it be. If it is not a vowel and not agnostic, we have a consonant\n",
    "            vowels = False\n",
    "    return representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_representation(representation):\n",
    "    '''\n",
    "    representation: list of booleans (representing stress pattern\n",
    "    \n",
    "    returns: string of the stress pattern\n",
    "    '''\n",
    "    string = \"\"\n",
    "    for boolean in representation: \n",
    "        if boolean:\n",
    "            string += 'T'\n",
    "        else:\n",
    "            string += 'F'\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions of which it is unclear whether they are still useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_realization_model(model, realization):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    assert(len(model) == len(realization))\n",
    "    \n",
    "    comparison = []\n",
    "    unequal_lengths = []\n",
    "    for i in np.arange(len(model)):\n",
    "        mod_word = build_syllable_representation(model[i])\n",
    "        act_word = build_syllable_representation(realization[i])\n",
    "        if len(mod_word) != len(act_word):\n",
    "            #print(\"not equal length\", i, mod_word, act_word)\n",
    "            unequal_lengths.append(i)\n",
    "            comparison.append(False)\n",
    "            continue\n",
    "        problem_encountered = False\n",
    "        for j in np.arange(len(mod_word)):\n",
    "            if mod_word[j] != act_word[j]:\n",
    "                problem_encountered = True\n",
    "                continue\n",
    "        comparison.append(not problem_encountered)\n",
    "    return comparison, unequal_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_nonmatches_metadata(df, comparison):\n",
    "    '''\n",
    "    Finds the non matches within the data set and puts the model and the realization next to each other\n",
    "    \n",
    "    df: data set\n",
    "    comparison: list of booleans that where true is a match and false is not a match\n",
    "    \n",
    "    returns a list of five-tuples of non-matching syllable structures preceded by the meta-data\n",
    "    '''\n",
    "    cases = []\n",
    "    for i, boolean in enumerate(comparison):\n",
    "        if not boolean:\n",
    "            cases.append((df.Name[i], df.Age[i], df.word[i], df.model[i], df.realization[i]))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_nonmatches(df, comparison):\n",
    "    '''\n",
    "    Finds the non matches within the data set and puts the model and the realization next to each other\n",
    "    \n",
    "    df: data set\n",
    "    comparison: list of booleans that where true is a match and false is not a match\n",
    "    \n",
    "    returns a list of pairs of non-matching syllable structures\n",
    "    '''\n",
    "    cases = []\n",
    "    for i, boolean in enumerate(comparison):\n",
    "        if not boolean:\n",
    "            cases.append((df.model[i], df.realization[i]))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(df, comparison, save=False):\n",
    "    '''\n",
    "    Calculates statistics on the syllable structure of the dataset \n",
    "    \n",
    "    df: the data frame on which the statistics need to be calculated\n",
    "    comparison: the list of booleans where true indicates model and realization match, and false that they do not match\n",
    "    save: optional argument on whether to save the statistics to a csv file\n",
    "    \n",
    "    returns five dictionaries with statistics\n",
    "    TODO TODO TODO \n",
    "    '''\n",
    "    stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act = {}, {}, {}, {}, {}\n",
    "    for i in np.arange(10):\n",
    "        stats_mod[i] = 0\n",
    "        stats_act[i] = 0\n",
    "        stats_match[i] = 0\n",
    "        stats_nonmatch_mod[i] = 0\n",
    "        stats_nonmatch_act[i] = 0\n",
    "    #print(comparison)\n",
    "    for i, boolean in enumerate(comparison):\n",
    "        rep_mod = build_syllable_representation(df.model[i])\n",
    "        rep_act = build_syllable_representation(df.realization[i])\n",
    "        stats_mod[len(rep_mod)] += 1\n",
    "        stats_act[len(rep_act)] += 1\n",
    "        if boolean:\n",
    "            stats_match[len(rep_mod)] += 1\n",
    "        else:\n",
    "            stats_nonmatch_mod[len(rep_mod)] += 1\n",
    "            stats_nonmatch_act[len(rep_act)] += 1\n",
    "    #print(stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act)\n",
    "    if save:\n",
    "        write_stats_to_csv('stats.csv', stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act)\n",
    "    return stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_iambic_bisyllabic_words(df):\n",
    "    filter_bisyl = [True if l==2 else False for l in df.rep_model.apply(len) ]#df.rep_model.apply(len) #and df.rep_model[1]\n",
    "    #print(filter_iamb)\n",
    "    filtered = df[filter_bisyl]\n",
    "    filter_iamb = [r[1] for r in filtered.rep_model]\n",
    "    return filtered[filter_iamb] #Second thing returns booleans, we are interested when these are True\n",
    "    \n",
    "def filter_trisyllabic_words(df):\n",
    "    filter_trisyl = [True if l==3 else False for l in df.rep_model.apply(len) ]#df.rep_model.apply(len) #and df.rep_model[1]\n",
    "    #print(filter_iamb)\n",
    "    return df[filter_trisyl]\n",
    "\n",
    "def add_heavy_fin_syl_column(df):\n",
    "    df['heavy_final_syl'] = df.model.apply(is_final_syllable_heavy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iambic_bysyl_investigation():\n",
    "    iamb_bisyl = filter_iambic_bisyllabic_words(df)\n",
    "    add_heavy_fin_syl_column(iamb_bisyl)\n",
    "    print(iamb_bisyl)\n",
    "    print(np.sum(iamb_bisyl.heavy_final_syl))\n",
    "    print(iamb_bisyl[ [not b for b in iamb_bisyl.heavy_final_syl] ])\n",
    "\n",
    "#write_df_to_csv('iamb_bisyl.csv', filter_iambic_bisyllabic_words(df))\n",
    "\n",
    "\n",
    "def trisyl_investigation(df):\n",
    "    # main function to collect trisyllabic words\n",
    "    df_trisyl = filter_trisyllabic_words(df)\n",
    "    write_df_to_csv('trisyl.csv', df_trisyl)\n",
    "    df_trisyl_unique = df_trisyl.drop_duplicates(subset = [\"word\"])\n",
    "    write_df_to_csv('trisyl_unique.csv', df_trisyl_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_final_syllable_heavy(word):\n",
    "    '''\n",
    "    DEPRECATED, JUST HERE TO MAKE THE TESTING CLASS HAPPY\n",
    "    Use the function in the Word class instead\n",
    "    '''\n",
    "    if word[-1] in ipa_vowels:\n",
    "        # if the last letter is a vowel, we only have a heavy syllable if it is a diphtong, so if the letter before it is also a vowel\n",
    "        return word[-2] in ipa_vowels\n",
    "    else: #so final letter in agnostic_symbols or consonants\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate how many words of different types there are\n",
    "Produces list of the different word type patterns and their occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_unique_words(df):\n",
    "    '''\n",
    "    Collects all unique words in the data set\n",
    "    \n",
    "    df: complete data set including representations\n",
    "    returns: set of words (in IPA)\n",
    "    '''\n",
    "    words = set()\n",
    "    for word in df['model']:\n",
    "        words.add(word)\n",
    "    return words\n",
    "\n",
    "def make_df_words_repr(words):\n",
    "    '''\n",
    "    Make new dataframe with just the words (in IPA) and the representation\n",
    "    \n",
    "    words: set of words (in IPA)\n",
    "    returns: dataframe with word and repr of word\n",
    "    '''\n",
    "    df = pd.DataFrame(columns=['word','representation'])\n",
    "    for word in words:\n",
    "        df = df.append({'word': word, 'representation': build_syllable_representation(word)}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def calculate_nr_word_types(df):\n",
    "    '''\n",
    "    calculates the number of occurrences of each word type\n",
    "    \n",
    "    df: dataframe with word (in IPA) and stringified representation\n",
    "    returns: counts of the representation\n",
    "    '''\n",
    "    # Lists are not hashable, so we stringify the list representation, which is hashable\n",
    "    strings = df['representation'].apply(stringify_representation)\n",
    "    return strings.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_type_investigation():\n",
    "    words = collect_unique_words(df)\n",
    "    words_reprs = make_df_words_repr(words)\n",
    "    counts = calculate_nr_word_types(words_reprs)\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTest(unittest.TestCase):\n",
    "    def test_build_syllable_representation(self, secondary=False):\n",
    "        '''\n",
    "        Tests the build_syllable_representation function with different examples\n",
    "        Also used to see if something breaks after adjusting\n",
    "        '''\n",
    "    \n",
    "        if not secondary:\n",
    "            #one syllable word, with bridge\n",
    "            self.assertEqual([True], build_syllable_representation('ˈbu̠t͡s'))\n",
    "            \n",
    "            #simple two syllable words with different stress\n",
    "            self.assertEqual([False, True], build_syllable_representation('koːˈlɛin'))\n",
    "            self.assertEqual([True, False], build_syllable_representation('ˈpukə'))\n",
    "            self.assertEqual([True, False], build_syllable_representation('ˈɡʊkʊk'))\n",
    "            \n",
    "            #other\n",
    "            self.assertEqual([True, False, False], build_syllable_representation('ˈʔaːˌkleːdə'))\n",
    "            \n",
    "            self.assertEqual([True, False], build_syllable_representation('ˈpinoːŭ'))\n",
    "            self.assertEqual([True, False, False], build_syllable_representation('ˈzeˌot͡jɑ̈s'))\n",
    "            self.assertEqual([True, False], build_syllable_representation('ˈnæˑŋi'))\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    def test_is_final_syllable_heavy(self):\n",
    "        self.assertEqual(True, is_final_syllable_heavy('ˈzeˌot͡jɑ̈s'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('koːˈlɛin'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('koˈnɛi'))\n",
    "        self.assertEqual(False, is_final_syllable_heavy('ˈpukə'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('ˈbu̠t͡s'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('kˈɑpχː'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('neː'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('fiˈjoʋ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce tables from Fikkert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce_tables(df, children_names):\n",
    "    '''\n",
    "    Reproduces the data from the tables from Fikkert, p. 25\n",
    "    That is, function calculates the total amount of model bisyllabic words and calculates \n",
    "    the percentage that is realized in a truncated way, differentiating between iambic and\n",
    "    trochaic words. \n",
    "    \n",
    "    df: the complete data from with representations\n",
    "    children_names: the names of the children for which the calculations need to be done\n",
    "    returns: dictionary with the child names and the totals of model bisyllabic words and truncated forms\n",
    "    '''\n",
    "    data_per_child = {}\n",
    "    for child in children_names:\n",
    "        ch_data = df[df['Name'] == child]\n",
    "        #print(ch_data)\n",
    "        total_bisyl_iamb = 0\n",
    "        total_bisyl_troc = 0\n",
    "        trunc_bisyl_iamb = 0\n",
    "        trunc_bisyl_troc = 0\n",
    "        for index, data_point in ch_data.iterrows(): \n",
    "            if len(data_point['rep_model'])== 2:\n",
    "                #if not data_point['rep_model'][0] and data_point['rep_model'][1]:\n",
    "                if data_point['rep_model'][1]:\n",
    "                    total_bisyl_iamb += 1\n",
    "                    if len(data_point['rep_realization']) == 1:\n",
    "                        trunc_bisyl_iamb += 1\n",
    "                #if data_point['rep_model'][0] and not data_point['rep_model'][1]:\n",
    "                if data_point['rep_model'][0]:\n",
    "                    total_bisyl_troc += 1\n",
    "                    if len(data_point['rep_realization']) == 1:\n",
    "                        trunc_bisyl_troc += 1\n",
    "        data_per_child[child] = (total_bisyl_iamb, total_bisyl_troc, trunc_bisyl_iamb, trunc_bisyl_troc)\n",
    "    return data_per_child\n",
    "\n",
    "def pretty_print_tables(data_per_child, children_names):\n",
    "    '''\n",
    "    Prints the percentages of truncated bisyllabic trochees and iambs\n",
    "    \n",
    "    data_per_child: dictionary with the child names and the totals of model bisyllabic words and truncated forms\n",
    "    children_names: the names of the children for which the data needs to be printed\n",
    "    \n",
    "    '''\n",
    "    for child in children_names:\n",
    "        data = data_per_child[child]\n",
    "        print(child, \":\")\n",
    "        print( (data[3]/data[1])*100 ) \n",
    "        print( (data[2]/data[0])*100 ) #trunc iamb divided by total iamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reproduce_tables():\n",
    "    '''\n",
    "    Reproduces the tables from Fikkert p. 25\n",
    "    '''\n",
    "    children_names = ['Catootje', 'David', 'Elke', 'Enzo', 'Eva', 'Jarmo', 'Leon', 'Leonie', 'Noortje', 'Robin', 'Tirza', 'Tom']\n",
    "    child_per_data = reproduce_tables(df, children_names)\n",
    "    pretty_print_tables(child_per_data, children_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "This section contains different mains that use the function above to extract (hopefully) useful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests\n",
    "test = MyTest()\n",
    "test.test_build_syllable_representation()\n",
    "test.test_is_final_syllable_heavy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and add representation column to the data\n",
    "#    Fikkert corpus/CLPF: data2.pkl\n",
    "#    Grimm corpus: Grimm.csv\n",
    "\n",
    "df = read_data(\"data2.pkl\")\n",
    "append_representation_to_dataframe(df)\n",
    "#print(df)\n",
    "write_df_to_csv('CLPF.csv', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name              Age        word        model   realization  \\\n",
      "16850  Jarmo  P1Y6M27DT0H0M0S         aai          ˈai          ˈaːi   \n",
      "16851  Jarmo  P1Y6M27DT0H0M0S      appels       ˈɑpəls         ˈaːʔe   \n",
      "16852  Jarmo  P1Y6M27DT0H0M0S        auto         ˈoto      ˈtɑutoŭ   \n",
      "16853  Jarmo  P1Y6M27DT0H0M0S        auto         ˈoto        ˈtatʰo   \n",
      "16854  Jarmo  P1Y6M27DT0H0M0S        auto         ˈoto         ˈɑtoː   \n",
      "...      ...              ...         ...          ...           ...   \n",
      "18386  Jarmo   P2Y3M9DT0H0M0S        yogi        ˈjoχi       ˈjoŭχi   \n",
      "18387  Jarmo   P2Y3M9DT0H0M0S  zebrapaard  ˈzebraˈpart  ˈsɪjɑ̈ˌpʋaˑt   \n",
      "18388  Jarmo   P2Y3M9DT0H0M0S      zitten        ˈzɪtə         ˈsitʉ   \n",
      "18389  Jarmo   P2Y3M9DT0H0M0S          zo         ˈzoː           ˈsɔ   \n",
      "18390  Jarmo   P2Y3M9DT0H0M0S          zo         ˈzoː         ˈsoŭ   \n",
      "\n",
      "                 rep_model       rep_realization  \n",
      "16850               [True]                [True]  \n",
      "16851        [True, False]                [True]  \n",
      "16852        [True, False]         [True, False]  \n",
      "16853        [True, False]         [True, False]  \n",
      "16854        [True, False]         [True, False]  \n",
      "...                    ...                   ...  \n",
      "18386        [True, False]         [True, False]  \n",
      "18387  [True, False, True]  [True, False, False]  \n",
      "18388        [True, False]         [True, False]  \n",
      "18389               [True]                [True]  \n",
      "18390               [True]                [True]  \n",
      "\n",
      "[1541 rows x 7 columns]\n",
      "P1Y10M28DT0H0M0S\n",
      "P1Y10M28DT0H0M0S\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Plot the vocabulary development of a specific child\n",
    "\n",
    "def investigate_child_development(name):\n",
    "    '''\n",
    "    TODO: needs to be adjusted for the patterns and such\n",
    "    '''\n",
    "    child = build_wordlists_for_child(name, df)\n",
    "    #print(leon.wordlists[0])\n",
    "    child.calculate_total_vocab_dev()\n",
    "\n",
    "leon = build_wordlists_for_child('Jarmo', df)\n",
    "print(leon.wordlists[0])\n",
    "print(leon.plot_vocab_dev(['TFF', 'FTF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF        1019\n",
      "T          691\n",
      "TFF        320\n",
      "FTF        112\n",
      "FT         104\n",
      "TFFF        61\n",
      "F           36\n",
      "FFT         30\n",
      "TTF         20\n",
      "FFTF        19\n",
      "TFTF        17\n",
      "TT          14\n",
      "FTFF        10\n",
      "TFT          7\n",
      "TFFFF        6\n",
      "FFFT         5\n",
      "TFFT         4\n",
      "FFTFF        4\n",
      "TFFTF        3\n",
      "FFFF         2\n",
      "FTFT         2\n",
      "FTFTF        2\n",
      "FF           2\n",
      "FFFTTF       1\n",
      "FFF          1\n",
      "FFTFFF       1\n",
      "FTFFFF       1\n",
      "TTFF         1\n",
      "TFTFF        1\n",
      "             1\n",
      "Name: representation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Investigate what word types occur how often\n",
    "\n",
    "word_type_investigation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catootje :\n",
      "6.0\n",
      "12.087912087912088\n",
      "David :\n",
      "5.150214592274678\n",
      "18.51851851851852\n",
      "Elke :\n",
      "11.080332409972298\n",
      "85.45454545454545\n",
      "Enzo :\n",
      "8.401084010840108\n",
      "30.0\n",
      "Eva :\n",
      "8.93371757925072\n",
      "62.96296296296296\n",
      "Jarmo :\n",
      "12.063492063492063\n",
      "68.57142857142857\n",
      "Leon :\n",
      "3.602305475504323\n",
      "22.916666666666664\n",
      "Leonie :\n",
      "7.87037037037037\n",
      "8.0\n",
      "Noortje :\n",
      "7.707910750507099\n",
      "54.54545454545454\n",
      "Robin :\n",
      "6.122448979591836\n",
      "37.03703703703704\n",
      "Tirza :\n",
      "6.432748538011696\n",
      "57.49999999999999\n",
      "Tom :\n",
      "9.632224168126093\n",
      "43.42105263157895\n"
     ]
    }
   ],
   "source": [
    "# Run reproduction of tables\n",
    "run_reproduce_tables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyternotebookvenv",
   "language": "python",
   "name": "jupyternotebookvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
