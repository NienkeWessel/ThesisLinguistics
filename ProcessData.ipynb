{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import unittest\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from dateutil import parser\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tolerance formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolerance_formula(N, e):\n",
    "    '''\n",
    "    Tolerance formula from Yang, p. 9\n",
    "    '''\n",
    "    print(N, e)\n",
    "    return e <= N/np.log(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data file operations\n",
    "This part of the code deals with file operations, such as reading and closing files\n",
    "\n",
    "## Preferably use the final function!\n",
    "Older ones are kind of deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(filename, df):\n",
    "    \"\"\"\n",
    "    Code from: https://www.kite.com/python/answers/how-to-save-a-pandas-dataframe-in-python\n",
    "    \"\"\"\n",
    "    df.to_pickle(filename)\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Code from: https://www.kite.com/python/answers/how-to-save-a-pandas-dataframe-in-python\n",
    "    \"\"\"\n",
    "    return pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_representation_to_dataframe(df):\n",
    "    '''\n",
    "    Appends the syllable representations of the model and realization to the dataframe \n",
    "    to have all information in one place\n",
    "    \n",
    "    df: data set, of which the representations need to be appended\n",
    "    \n",
    "    No return, as it mutates the df object\n",
    "    '''\n",
    "    df['rep_model'] = df.model.apply(build_syllable_representation)\n",
    "    df['rep_realization'] = df.realization.apply(build_syllable_representation)\n",
    "    #print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nonmatches_to_csv(filename, df, comparison, header = ['Name', 'Age', 'word', 'model','realization','stressmodel','stressrealization'], apply_filter=True):\n",
    "    with open(filename, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write the header\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # write the data\n",
    "        for n, a, word, w,v in collect_nonmatches_metadata(df, comparison):\n",
    "            if not apply_filter:\n",
    "                writer.writerow([n,a,word,w, v, build_syllable_representation(w), build_syllable_representation(v)])\n",
    "            else:\n",
    "                rep_w = build_syllable_representation(w)\n",
    "                rep_v = build_syllable_representation(v)\n",
    "                # If at least one of the two representations has 2 or more syllables, then we are interested\n",
    "                if len(rep_w) >= 2 or len(rep_v) >= 2: \n",
    "                    writer.writerow([n,a,word,w, v, rep_w, rep_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stats_to_csv(filename, a,b,c,d,e):\n",
    "    '''\n",
    "    stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act\n",
    "    '''\n",
    "    with open(filename, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write the header\n",
    "        writer.writerow(['number','modellengthall','realizationlengthall','lengthmatch', 'modellengthnonmatch', 'realizationlengthnonmatch'])\n",
    "\n",
    "        # write the data\n",
    "        for i in range(10):\n",
    "            writer.writerow([i, a[i], b[i], c[i], d[i], e[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_csv(filename, df):\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, written, model, realization, rep_model, rep_realization):\n",
    "        self.written = written\n",
    "        self.model = model\n",
    "        self.realization = realization\n",
    "        self.rep_model = rep_model\n",
    "        self.rep_realization = rep_realization\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.written == other.written\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.written.__hash__()\n",
    "\n",
    "    def is_bisyl(self):\n",
    "        return len(self.rep_model) == 2\n",
    "    \n",
    "    def is_iambic_bisyl(self):\n",
    "        if len(self.rep_model) == 2:\n",
    "            return self.rep_model[1]\n",
    "        else:\n",
    "            return False \n",
    "    \n",
    "    def is_final_syllable_heavy(self):\n",
    "        if self.model[-1] in ipa_vowels:\n",
    "            # if the last letter is a vowel, we only have a heavy syllable if it is a diphtong, so if the letter before it is also a vowel\n",
    "            return self.model[-2] in ipa_vowels\n",
    "        else: #so final letter in agnostic_symbols or consonants\n",
    "            return True\n",
    "    \n",
    "    def matches_pattern(self, pattern, model = True):\n",
    "        '''\n",
    "        Calculates whether the word matches the stress pattern\n",
    "        \n",
    "        pattern: string of F(alse) and T(rue) or A(gnostic) indicating the stress placement\n",
    "        model: boolean which indicates whether to match to the model representation (True) or realization representation (False)\n",
    "        Agnostic (or any other symbol) can be used to indicate that one does not care about the stress placement\n",
    "        \n",
    "        return: \n",
    "        '''\n",
    "        if model:\n",
    "            word = self.rep_model\n",
    "        else:\n",
    "            word = self.rep_realization\n",
    "        \n",
    "        # Initial check for length match. If not equal, no point in persuing (and prevents out of bound errors later on)\n",
    "        if len(pattern) != len(word):\n",
    "            return False\n",
    "        \n",
    "        for i,c in enumerate(pattern):\n",
    "            if c == 'T':\n",
    "                if not word[i]:\n",
    "                    return False\n",
    "            if c == 'F':\n",
    "                if word[i]:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordlist class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordList:\n",
    "    \n",
    "    def __init__(self, time ):\n",
    "        '''\n",
    "        time: the point in time to which this wordlist refers\n",
    "        '''\n",
    "        pass\n",
    "        #self.time = time\n",
    "        #self.wordlist\n",
    "        \n",
    "    def __cmp__(self, other):\n",
    "        return cmp(self.age, other.age)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.age < other.age\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"%s with length %s\" % (self.age, len(self.wordlist))\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        pass\n",
    "\n",
    "    def add_prev_state_wordlist(prev_wordlist):\n",
    "        for word in prev_wordlist.wordlist:\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def parse_age(self):\n",
    "        numbers = re.findall('\\d+', self.time)\n",
    "        # the age in months with a approximation for the number of days\n",
    "        return float(numbers[0])*12 + float(numbers[1]) + float(numbers[2])/31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniqueWordList(WordList):\n",
    "    \n",
    "    def __init__(self, time ):\n",
    "        '''\n",
    "        time: the point in time to which this wordlist refers\n",
    "        '''\n",
    "        self.time = time\n",
    "        self.age = self.parse_age()\n",
    "        self.wordlist = set()\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        self.wordlist.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllWordList(WordList):\n",
    "    \n",
    "    def __init__(self, time ):\n",
    "        '''\n",
    "        time: the point in time to which this wordlist refers\n",
    "        '''\n",
    "        self.time = time\n",
    "        self.age = self.parse_age()\n",
    "        self.wordlist = []    \n",
    "    \n",
    "    def add_word(self, word):\n",
    "        self.wordlist.append(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child development class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChildDevelopment:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        name: child's name (just for bookkeeping purposes)\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.wordlists = []\n",
    "        self.complete_wordlists = []\n",
    "    \n",
    "    \n",
    "    def add_wordlist(self, wordlist, complete = False):\n",
    "        '''\n",
    "        Appends wordlist to the wordlists of the child\n",
    "        \n",
    "        wordlist: the wordlist to be added\n",
    "        '''\n",
    "        if not complete:\n",
    "            self.wordlists.append(wordlist)\n",
    "        else: \n",
    "            self.complete_wordlists.append(wordlist)\n",
    "\n",
    "    def collect_ages(self):\n",
    "        '''\n",
    "        Collects all the ages of the different wordlists and saves in ages attribute\n",
    "        '''\n",
    "        self.ages = []\n",
    "        for wordlist in self.complete_wordlists:\n",
    "            self.ages.append(wordlist.age)\n",
    "        \n",
    "    def calculate_total_vocab_dev(self):\n",
    "        '''\n",
    "        Calculates the development of the vocabulary size, i.e. how the vocabulary grows through time\n",
    "        \n",
    "        returns: list of cumulative vocabulary sizes\n",
    "        \n",
    "        Todo: Add something similar for the dates so that we have those\n",
    "        '''\n",
    "        print(self.wordlists[0])\n",
    "        development = []\n",
    "        total_wordlist = set()\n",
    "        for wordlist in self.wordlists:\n",
    "            \n",
    "            for word in wordlist.wordlist:\n",
    "                total_wordlist.add(word)\n",
    "            development.append(len(total_wordlist))\n",
    "        return development\n",
    "\n",
    "    \n",
    "    def calculate_development_by_patterns(self, patterns):\n",
    "        '''\n",
    "        Calculates the wordlists for a list of patterns and the total development\n",
    "        For efficiency, this is done at once (building wordlists is expensive)\n",
    "        \n",
    "        patterns: the patterns one wants the developments of\n",
    "        return: list of developments for the patterns\n",
    "        '''\n",
    "        developments_counts = {}\n",
    "        developments = {}\n",
    "        \n",
    "        for p in patterns:\n",
    "            developments[p] = set()\n",
    "            developments_counts[p] = []\n",
    "        \n",
    "        \n",
    "        for wordlist in self.wordlists:\n",
    "            for word in wordlist.wordlist:\n",
    "                for p in patterns:\n",
    "                    if word.matches_pattern(p):\n",
    "                        developments[p].add(word)\n",
    "            for p in patterns:\n",
    "                developments_counts[p].append(len(developments[p]))\n",
    "        \n",
    "        return developments_counts, developments\n",
    "        \n",
    "    def calculate_progress_of_patterns_old(self, goal_patterns, real_patterns):\n",
    "        '''\n",
    "        Calculates, through time, how certain \n",
    "        \n",
    "        TODO: fix that if you give two of the same pattern, the counts doubles\n",
    "        Idea: instead of separate goal_pattern, make real_patterns linked to goal_pattern so no\n",
    "        need to fill in same goal pattern twice\n",
    "        '''\n",
    "        goal_counts = {}\n",
    "        real_counts = {}\n",
    "        \n",
    "        for i, p in enumerate(goal_patterns):\n",
    "            goal_counts[p] = np.zeros(len(self.complete_wordlists))\n",
    "            real_counts[real_patterns[i]] = np.zeros(len(self.complete_wordlists))\n",
    "        \n",
    "        for j, wordlist in enumerate(self.complete_wordlists):\n",
    "            for word in wordlist.wordlist:\n",
    "                for i, p in enumerate(goal_patterns):\n",
    "                    # loop through the goal_patterns and count how many of those occurred in the data set\n",
    "                    # Then count how many of them had the real_pattern as well\n",
    "                    \n",
    "                    if word.matches_pattern(p):\n",
    "                        goal_counts[p][j] += 1\n",
    "                        if word.matches_pattern(real_patterns[i], model = False): # If realizations matches the corresponding real pattern\n",
    "                            real_counts[real_patterns[i]][j] += 1\n",
    "                            \n",
    "        return goal_counts, real_counts\n",
    "    \n",
    "    def calculate_progress_of_patterns(self, patterns):\n",
    "        '''\n",
    "        Calculates, through time, how certain \n",
    "        \n",
    "        TODO: fix that if you give two of the same pattern, the counts doubles\n",
    "        Idea: instead of separate goal_pattern, make real_patterns linked to goal_pattern so no\n",
    "        need to fill in same goal pattern twice\n",
    "        '''\n",
    "        #iamb_bisyl_phases = \n",
    "        #patterns = {'FT': ['T', 'TF', 'TT', 'FT', 'AA']}\n",
    "        \n",
    "        # Goal structure:\n",
    "        # dictionary:\n",
    "        # { 'FT' :  ([], {'T': [], 'TF': [] } ),\n",
    "        #   'TF' :  ([], {'T': [], 'TF': [] } )\n",
    "        # }\n",
    "        \n",
    "        counts = {}\n",
    "        \n",
    "        for p in patterns:\n",
    "            counts[p] = (np.zeros(len(self.complete_wordlists)), {})\n",
    "            for rp in p:\n",
    "                counts[p][1][rp] = np.zeros(len(self.complete_wordlists))\n",
    "        \n",
    "        #for \n",
    "        \n",
    "        for j, wordlist in enumerate(self.complete_wordlists):\n",
    "            for word in wordlist.wordlist:\n",
    "                for p in patterns:\n",
    "                    # loop through the patterns and count how many of those occurred in the data set\n",
    "                    # Then count how many of them had the real_pattern as well\n",
    "                    \n",
    "                    if word.matches_pattern(p):\n",
    "                        counts[p][0][j] += 1\n",
    "                        for real_pat in patterns[p]:\n",
    "                            if word.matches_pattern(real_pat, model = False): # If realizations matches the corresponding real pattern\n",
    "                                counts[p][1][real_pat][j] += 1\n",
    "                            \n",
    "        return counts\n",
    "    \n",
    "    \n",
    "    def determine_tolerance(self, total, exceptions):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        tolerance = []\n",
    "        for i in range(len(total)):\n",
    "            tolerance.append(tolerance_formula(total[i], exceptions[i]))\n",
    "        print(tolerance)\n",
    "        \n",
    "    \n",
    "    def plot_vocab_dev_bisyl(self):\n",
    "        development_bisyl, development_bisyl_iamb = self.calculate_bisyl_vocab_dev()\n",
    "        total_dev = self.calculate_total_vocab_dev()\n",
    "        \n",
    "        self.determine_tolerance(development_bisyl, development_bisyl_iamb)\n",
    "        \n",
    "        plt.plot(self.ages, total_dev, label='Total vocabulary')\n",
    "        plt.plot(self.ages, development_bisyl, label='Bisyllabic words')\n",
    "        plt.plot(self.ages, development_bisyl_iamb, label='Bisyllabic iambic words')\n",
    "        plt.title('Development of ' + self.name)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def plot_vocab_dev(self, patterns):\n",
    "        developments_counts, developments = self.calculate_development_by_patterns(patterns)\n",
    "        total_dev = self.calculate_total_vocab_dev()\n",
    "        \n",
    "        #self.determine_tolerance(development_bisyl, development_bisyl_iamb)\n",
    "        \n",
    "        plt.plot(self.ages, total_dev, label='Total vocabulary')\n",
    "        for p in patterns:\n",
    "            plt.plot(self.ages, developments_counts[p], label=p)\n",
    "        plt.title('Development of ' + self.name)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def build_complete_wordlists(self, df):\n",
    "        '''\n",
    "        fills the complete_wordlists attribute based on the words in df\n",
    "        \n",
    "        df: the complete dataframe (with representations)\n",
    "        '''\n",
    "        df_child = df[df['Name'] == self.name]\n",
    "        indices = df[df['Name'] == self.name].index\n",
    "        prev_time = df_child.at[indices[0],'Age']\n",
    "        wordlist = AllWordList(prev_time)\n",
    "        for index, data_point in df_child.iterrows(): # Might be slow, see https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "            #print(data_point)\n",
    "            time = data_point['Age']\n",
    "            if prev_time != time: \n",
    "                self.add_wordlist(wordlist, complete = True)\n",
    "                wordlist = AllWordList(time)\n",
    "\n",
    "            word = Word(data_point['word'], data_point['model'], data_point['realization'], data_point['rep_model'], data_point['rep_realization'])\n",
    "            wordlist.add_word(word)\n",
    "\n",
    "            prev_time = time\n",
    "        self.complete_wordlists.sort()\n",
    "        \n",
    "        #This line should be somewhere else, make sure to call if after making wordlists\n",
    "        self.collect_ages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wordlists_for_child(name, df):\n",
    "    '''\n",
    "    builds the child development object and fills it with word lists through time\n",
    "    Assumes df is not shuffled (i.e. that the words from the same time point are next to each other)\n",
    "    \n",
    "    name: child name\n",
    "    df: complete dataframe\n",
    "    returns: child development object\n",
    "    \n",
    "    TODO: Maybe move to __init__ of child\n",
    "    '''\n",
    "    df_child = df[df['Name'] == name]\n",
    "    indices = df[df['Name'] == name].index\n",
    "    print(df_child)\n",
    "    prev_time = df_child.at[indices[0],'Age']\n",
    "    child_dev = ChildDevelopment(name)\n",
    "    wordlist = UniqueWordList(prev_time)\n",
    "    for index, data_point in df_child.iterrows(): # Might be slow, see https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "        #print(data_point)\n",
    "        time = data_point['Age']\n",
    "        if prev_time != time: \n",
    "            child_dev.add_wordlist(wordlist)\n",
    "            wordlist = UniqueWordList(time)\n",
    "        \n",
    "        word = Word(data_point['word'], data_point['model'], data_point['realization'], data_point['rep_model'], data_point['rep_realization'])\n",
    "        wordlist.add_word(word)\n",
    "        \n",
    "        prev_time = time\n",
    "    child_dev.wordlists.sort()\n",
    "    return(child_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_vowels = ['a', 'ɑ', 'œ', 'æ', 'y', 'o', 'ɑ̈', 'i', 'u', 'ɪ', 'ə', 'ɛ', 'e', 'ɔ', 'ʌ', 'ø̈', 'ɛ̝','ʉ', 'œ̞', 'œ', 'ɛ̞', 'ʔ', 'ɒ','ø', 'æ̝', 'ə̆', 'o͡', 'o̝', 'ʊ', 'ɯ']#, '͡'] \n",
    "agnostic_symbols = ['͡', 'ː', 'ˑ'] # symbols that can either be a vowel or consonant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_syllable_representation(word, secondary=False):\n",
    "    \"\"\"\n",
    "    word: the word of which you want the syllable representation\n",
    "    \n",
    "    Returns the representation of the syllable in the form of a list of booleans, where true represents stressed and false unstressed\n",
    "    \"\"\"\n",
    "    if not isinstance(word, str):\n",
    "        return []\n",
    "    \n",
    "    representation = []\n",
    "    stressed = False\n",
    "    vowels = False\n",
    "    for c in list(word):\n",
    "        #print(c)\n",
    "        if secondary and (c == \"ˈ\" or c == \"ˌ\"):\n",
    "            stressed = True\n",
    "        elif not secondary and c == \"ˈ\":\n",
    "            stressed = True\n",
    "        elif c in ipa_vowels:\n",
    "            if not vowels:\n",
    "                vowels = True\n",
    "                representation.append(stressed)\n",
    "                stressed = False\n",
    "        elif c not in agnostic_symbols: #if we do not know whether something is a vowel or consonant, we leave it be. If it is not a vowel and not agnostic, we have a consonant\n",
    "            vowels = False\n",
    "    return representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_representation(representation):\n",
    "    '''\n",
    "    representation: list of booleans (representing stress pattern\n",
    "    \n",
    "    returns: string of the stress pattern\n",
    "    '''\n",
    "    string = \"\"\n",
    "    for boolean in representation: \n",
    "        if boolean:\n",
    "            string += 'T'\n",
    "        else:\n",
    "            string += 'F'\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions of which it is unclear whether they are still useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_realization_model(model, realization):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    assert(len(model) == len(realization))\n",
    "    \n",
    "    comparison = []\n",
    "    unequal_lengths = []\n",
    "    for i in np.arange(len(model)):\n",
    "        mod_word = build_syllable_representation(model[i])\n",
    "        act_word = build_syllable_representation(realization[i])\n",
    "        if len(mod_word) != len(act_word):\n",
    "            #print(\"not equal length\", i, mod_word, act_word)\n",
    "            unequal_lengths.append(i)\n",
    "            comparison.append(False)\n",
    "            continue\n",
    "        problem_encountered = False\n",
    "        for j in np.arange(len(mod_word)):\n",
    "            if mod_word[j] != act_word[j]:\n",
    "                problem_encountered = True\n",
    "                continue\n",
    "        comparison.append(not problem_encountered)\n",
    "    return comparison, unequal_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_nonmatches_metadata(df, comparison):\n",
    "    '''\n",
    "    Finds the non matches within the data set and puts the model and the realization next to each other\n",
    "    \n",
    "    df: data set\n",
    "    comparison: list of booleans that where true is a match and false is not a match\n",
    "    \n",
    "    returns a list of five-tuples of non-matching syllable structures preceded by the meta-data\n",
    "    '''\n",
    "    cases = []\n",
    "    for i, boolean in enumerate(comparison):\n",
    "        if not boolean:\n",
    "            cases.append((df.Name[i], df.Age[i], df.word[i], df.model[i], df.realization[i]))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_nonmatches(df, comparison):\n",
    "    '''\n",
    "    Finds the non matches within the data set and puts the model and the realization next to each other\n",
    "    \n",
    "    df: data set\n",
    "    comparison: list of booleans that where true is a match and false is not a match\n",
    "    \n",
    "    returns a list of pairs of non-matching syllable structures\n",
    "    '''\n",
    "    cases = []\n",
    "    for i, boolean in enumerate(comparison):\n",
    "        if not boolean:\n",
    "            cases.append((df.model[i], df.realization[i]))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(df, comparison, save=False):\n",
    "    '''\n",
    "    Calculates statistics on the syllable structure of the dataset \n",
    "    \n",
    "    df: the data frame on which the statistics need to be calculated\n",
    "    comparison: the list of booleans where true indicates model and realization match, and false that they do not match\n",
    "    save: optional argument on whether to save the statistics to a csv file\n",
    "    \n",
    "    returns five dictionaries with statistics\n",
    "    TODO TODO TODO \n",
    "    '''\n",
    "    stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act = {}, {}, {}, {}, {}\n",
    "    for i in np.arange(10):\n",
    "        stats_mod[i] = 0\n",
    "        stats_act[i] = 0\n",
    "        stats_match[i] = 0\n",
    "        stats_nonmatch_mod[i] = 0\n",
    "        stats_nonmatch_act[i] = 0\n",
    "    #print(comparison)\n",
    "    for i, boolean in enumerate(comparison):\n",
    "        rep_mod = build_syllable_representation(df.model[i])\n",
    "        rep_act = build_syllable_representation(df.realization[i])\n",
    "        stats_mod[len(rep_mod)] += 1\n",
    "        stats_act[len(rep_act)] += 1\n",
    "        if boolean:\n",
    "            stats_match[len(rep_mod)] += 1\n",
    "        else:\n",
    "            stats_nonmatch_mod[len(rep_mod)] += 1\n",
    "            stats_nonmatch_act[len(rep_act)] += 1\n",
    "    #print(stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act)\n",
    "    if save:\n",
    "        write_stats_to_csv('stats.csv', stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act)\n",
    "    return stats_mod, stats_act, stats_match, stats_nonmatch_mod, stats_nonmatch_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_iambic_bisyllabic_words(df):\n",
    "    filter_bisyl = [True if l==2 else False for l in df.rep_model.apply(len) ]#df.rep_model.apply(len) #and df.rep_model[1]\n",
    "    #print(filter_iamb)\n",
    "    filtered = df[filter_bisyl]\n",
    "    filter_iamb = [r[1] for r in filtered.rep_model]\n",
    "    return filtered[filter_iamb] #Second thing returns booleans, we are interested when these are True\n",
    "    \n",
    "def filter_trisyllabic_words(df):\n",
    "    filter_trisyl = [True if l==3 else False for l in df.rep_model.apply(len) ]#df.rep_model.apply(len) #and df.rep_model[1]\n",
    "    #print(filter_iamb)\n",
    "    return df[filter_trisyl]\n",
    "\n",
    "def add_heavy_fin_syl_column(df):\n",
    "    df['heavy_final_syl'] = df.model.apply(is_final_syllable_heavy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iambic_bysyl_investigation():\n",
    "    iamb_bisyl = filter_iambic_bisyllabic_words(df)\n",
    "    add_heavy_fin_syl_column(iamb_bisyl)\n",
    "    print(iamb_bisyl)\n",
    "    print(np.sum(iamb_bisyl.heavy_final_syl))\n",
    "    print(iamb_bisyl[ [not b for b in iamb_bisyl.heavy_final_syl] ])\n",
    "\n",
    "#write_df_to_csv('iamb_bisyl.csv', filter_iambic_bisyllabic_words(df))\n",
    "\n",
    "\n",
    "def trisyl_investigation(df):\n",
    "    # main function to collect trisyllabic words\n",
    "    df_trisyl = filter_trisyllabic_words(df)\n",
    "    write_df_to_csv('trisyl.csv', df_trisyl)\n",
    "    df_trisyl_unique = df_trisyl.drop_duplicates(subset = [\"word\"])\n",
    "    write_df_to_csv('trisyl_unique.csv', df_trisyl_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_final_syllable_heavy(word):\n",
    "    '''\n",
    "    DEPRECATED, JUST HERE TO MAKE THE TESTING CLASS HAPPY\n",
    "    Use the function in the Word class instead\n",
    "    '''\n",
    "    if word[-1] in ipa_vowels:\n",
    "        # if the last letter is a vowel, we only have a heavy syllable if it is a diphtong, so if the letter before it is also a vowel\n",
    "        return word[-2] in ipa_vowels\n",
    "    else: #so final letter in agnostic_symbols or consonants\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate how many words of different types there are\n",
    "Produces list of the different word type patterns and their occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_unique_words(df):\n",
    "    '''\n",
    "    Collects all unique words in the data set\n",
    "    \n",
    "    df: complete data set including representations\n",
    "    returns: set of words (in IPA)\n",
    "    '''\n",
    "    words = set()\n",
    "    for word in df['model']:\n",
    "        words.add(word)\n",
    "    return words\n",
    "\n",
    "def make_df_words_repr(words):\n",
    "    '''\n",
    "    Make new dataframe with just the words (in IPA) and the representation\n",
    "    \n",
    "    words: set of words (in IPA)\n",
    "    returns: dataframe with word and repr of word\n",
    "    '''\n",
    "    df = pd.DataFrame(columns=['word','representation'])\n",
    "    for word in words:\n",
    "        df = df.append({'word': word, 'representation': build_syllable_representation(word)}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def calculate_nr_word_types(df):\n",
    "    '''\n",
    "    calculates the number of occurrences of each word type\n",
    "    \n",
    "    df: dataframe with word (in IPA) and stringified representation\n",
    "    returns: counts of the representation\n",
    "    '''\n",
    "    # Lists are not hashable, so we stringify the list representation, which is hashable\n",
    "    strings = df['representation'].apply(stringify_representation)\n",
    "    return strings.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_type_investigation():\n",
    "    words = collect_unique_words(df)\n",
    "    words_reprs = make_df_words_repr(words)\n",
    "    counts = calculate_nr_word_types(words_reprs)\n",
    "    print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTest(unittest.TestCase):\n",
    "    def test_build_syllable_representation(self, secondary=False):\n",
    "        '''\n",
    "        Tests the build_syllable_representation function with different examples\n",
    "        Also used to see if something breaks after adjusting\n",
    "        '''\n",
    "    \n",
    "        if not secondary:\n",
    "            #one syllable word, with bridge\n",
    "            self.assertEqual([True], build_syllable_representation('ˈbu̠t͡s'))\n",
    "            \n",
    "            #simple two syllable words with different stress\n",
    "            self.assertEqual([False, True], build_syllable_representation('koːˈlɛin'))\n",
    "            self.assertEqual([True, False], build_syllable_representation('ˈpukə'))\n",
    "            self.assertEqual([True, False], build_syllable_representation('ˈɡʊkʊk'))\n",
    "            \n",
    "            #other\n",
    "            self.assertEqual([True, False, False], build_syllable_representation('ˈʔaːˌkleːdə'))\n",
    "            \n",
    "            self.assertEqual([True, False], build_syllable_representation('ˈpinoːŭ'))\n",
    "            self.assertEqual([True, False, False], build_syllable_representation('ˈzeˌot͡jɑ̈s'))\n",
    "            self.assertEqual([True, False], build_syllable_representation('ˈnæˑŋi'))\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    def test_is_final_syllable_heavy(self):\n",
    "        self.assertEqual(True, is_final_syllable_heavy('ˈzeˌot͡jɑ̈s'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('koːˈlɛin'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('koˈnɛi'))\n",
    "        self.assertEqual(False, is_final_syllable_heavy('ˈpukə'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('ˈbu̠t͡s'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('kˈɑpχː'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('neː'))\n",
    "        self.assertEqual(True, is_final_syllable_heavy('fiˈjoʋ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce tables from Fikkert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce_tables(df, children_names):\n",
    "    '''\n",
    "    Reproduces the data from the tables from Fikkert, p. 25\n",
    "    That is, function calculates the total amount of model bisyllabic words and calculates \n",
    "    the percentage that is realized in a truncated way, differentiating between iambic and\n",
    "    trochaic words. \n",
    "    \n",
    "    df: the complete data from with representations\n",
    "    children_names: the names of the children for which the calculations need to be done\n",
    "    returns: dictionary with the child names and the totals of model bisyllabic words and truncated forms\n",
    "    '''\n",
    "    data_per_child = {}\n",
    "    for child in children_names:\n",
    "        ch_data = df[df['Name'] == child]\n",
    "        #print(ch_data)\n",
    "        total_bisyl_iamb = 0\n",
    "        total_bisyl_troc = 0\n",
    "        trunc_bisyl_iamb = 0\n",
    "        trunc_bisyl_troc = 0\n",
    "        for index, data_point in ch_data.iterrows(): \n",
    "            if len(data_point['rep_model'])== 2:\n",
    "                #if not data_point['rep_model'][0] and data_point['rep_model'][1]:\n",
    "                if data_point['rep_model'][1]:\n",
    "                    total_bisyl_iamb += 1\n",
    "                    if len(data_point['rep_realization']) == 1:\n",
    "                        trunc_bisyl_iamb += 1\n",
    "                #if data_point['rep_model'][0] and not data_point['rep_model'][1]:\n",
    "                if data_point['rep_model'][0]:\n",
    "                    total_bisyl_troc += 1\n",
    "                    if len(data_point['rep_realization']) == 1:\n",
    "                        trunc_bisyl_troc += 1\n",
    "        data_per_child[child] = (total_bisyl_iamb, total_bisyl_troc, trunc_bisyl_iamb, trunc_bisyl_troc)\n",
    "    return data_per_child\n",
    "\n",
    "def pretty_print_tables(data_per_child, children_names):\n",
    "    '''\n",
    "    Prints the percentages of truncated bisyllabic trochees and iambs\n",
    "    \n",
    "    data_per_child: dictionary with the child names and the totals of model bisyllabic words and truncated forms\n",
    "    children_names: the names of the children for which the data needs to be printed\n",
    "    \n",
    "    '''\n",
    "    for child in children_names:\n",
    "        data = data_per_child[child]\n",
    "        print(child, \":\")\n",
    "        print( (data[3]/data[1])*100 ) \n",
    "        print( (data[2]/data[0])*100 ) #trunc iamb divided by total iamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reproduce_tables():\n",
    "    '''\n",
    "    Reproduces the tables from Fikkert p. 25\n",
    "    '''\n",
    "    children_names = ['Catootje', 'David', 'Elke', 'Enzo', 'Eva', 'Jarmo', 'Leon', 'Leonie', 'Noortje', 'Robin', 'Tirza', 'Tom']\n",
    "    child_per_data = reproduce_tables(df, children_names)\n",
    "    pretty_print_tables(child_per_data, children_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase development\n",
    "\n",
    "This part of the code goes through the phase development of the children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1\n",
    "\n",
    "In phase 1, the child truncates the bisyllabic word and produces it as monosyllabic. Only the stressed syllable of the adult target is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_phase_1_dev(child, patterns):\n",
    "    goal_counts, real_counts = child.calculate_progress_of_patterns(patterns)\n",
    "    print(goal_counts)\n",
    "    print(real_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "This section contains different mains that use the function above to extract (hopefully) useful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests\n",
    "test = MyTest()\n",
    "test.test_build_syllable_representation()\n",
    "test.test_is_final_syllable_heavy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and add representation column to the data\n",
    "#    Fikkert corpus/CLPF: data2.pkl\n",
    "#    Grimm corpus: Grimm.pkl\n",
    "\n",
    "df = read_data(\"data2.pkl\")\n",
    "append_representation_to_dataframe(df)\n",
    "#print(df)\n",
    "write_df_to_csv('CLPF.csv', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name               Age       word      model  realization  \\\n",
      "0     Leon  P1Y10M28DT0H0M0S  aankleden  ˈankledən  ˈʔaːˌkleːdə   \n",
      "1     Leon  P1Y10M28DT0H0M0S        aap        ˈap         ˈʔap   \n",
      "2     Leon  P1Y10M28DT0H0M0S      ander     ˈɑndəɹ        ˈʔɑnə   \n",
      "3     Leon  P1Y10M28DT0H0M0S       auto       ˈoto       ʔɑˈtoː   \n",
      "4     Leon  P1Y10M28DT0H0M0S        bal       ˈbɑl         ˈpɑl   \n",
      "...    ...               ...        ...        ...          ...   \n",
      "2553  Leon   P2Y0M10DT0H0M0S        wel       ˈʋɛl         ˈʋa̝   \n",
      "2554  Leon   P2Y0M10DT0H0M0S        wel       ˈʋɛl        ˈʋʉ̹l   \n",
      "2555  Leon   P2Y0M10DT0H0M0S        wel       ˈʋɛl        ˈʋɛ̝l   \n",
      "2556  Leon   P2Y0M10DT0H0M0S        wel       ˈʋɛl         ˈʋɛə   \n",
      "2557  Leon   P2Y0M10DT0H0M0S      zusje    ˈzœs͡jə       ˈsʉʃ̟ə   \n",
      "\n",
      "                 rep_model       rep_realization  \n",
      "0     [True, False, False]  [True, False, False]  \n",
      "1                   [True]                [True]  \n",
      "2            [True, False]         [True, False]  \n",
      "3            [True, False]         [False, True]  \n",
      "4                   [True]                [True]  \n",
      "...                    ...                   ...  \n",
      "2553                [True]                [True]  \n",
      "2554                [True]                [True]  \n",
      "2555                [True]                [True]  \n",
      "2556                [True]                [True]  \n",
      "2557         [True, False]         [True, False]  \n",
      "\n",
      "[2558 rows x 7 columns]\n",
      "22.032258064516128 with length 87\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[22.032258064516128 with length 131, 22.483870967741936 with length 161, 22.903225806451612 with length 184, 23.387096774193548 with length 148, 23.838709677419356 with length 158, 24.741935483870968 with length 119, 25.225806451612904 with length 124, 25.64516129032258 with length 86, 26.129032258064516 with length 88, 26.64516129032258 with length 52, 27.129032258064516 with length 73, 27.580645161290324 with length 72, 28.032258064516128 with length 79, 28.483870967741936 with length 75, 28.93548387096774 with length 125, 29.419354838709676 with length 74, 29.838709677419356 with length 96, 30.548387096774192 with length 56, 31.032258064516128 with length 94, 31.677419354838708 with length 169, 32.16129032258065 with length 153, 32.61290322580645 with length 94]\n",
      "22.032258064516128 with length 131\n"
     ]
    }
   ],
   "source": [
    "# Plot the vocabulary development of a specific child\n",
    "\n",
    "def investigate_child_development(name):\n",
    "    '''\n",
    "    TODO: needs to be adjusted for the patterns and such\n",
    "    '''\n",
    "    child = build_wordlists_for_child(name, df)\n",
    "    #print(leon.wordlists[0])\n",
    "    child.calculate_total_vocab_dev()\n",
    "\n",
    "leon = build_wordlists_for_child('Leon', df)\n",
    "#print(leon.wordlists[0])\n",
    "leon.build_complete_wordlists(df)\n",
    "\n",
    "print(leon.plot_vocab_dev(['TFF', 'FTF']))\n",
    "print(leon.complete_wordlists)\n",
    "print(leon.complete_wordlists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF        1019\n",
      "T          691\n",
      "TFF        320\n",
      "FTF        112\n",
      "FT         104\n",
      "TFFF        61\n",
      "F           36\n",
      "FFT         30\n",
      "TTF         20\n",
      "FFTF        19\n",
      "TFTF        17\n",
      "TT          14\n",
      "FTFF        10\n",
      "TFT          7\n",
      "TFFFF        6\n",
      "FFFT         5\n",
      "FFTFF        4\n",
      "TFFT         4\n",
      "TFFTF        3\n",
      "FFFF         2\n",
      "FTFT         2\n",
      "FTFTF        2\n",
      "FF           2\n",
      "FFFTTF       1\n",
      "FFTFFF       1\n",
      "TTFF         1\n",
      "FFF          1\n",
      "TFTFF        1\n",
      "FTFFFF       1\n",
      "             1\n",
      "Name: representation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Investigate what word types occur how often\n",
    "\n",
    "word_type_investigation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catootje :\n",
      "6.0\n",
      "12.087912087912088\n",
      "David :\n",
      "5.150214592274678\n",
      "18.51851851851852\n",
      "Elke :\n",
      "11.080332409972298\n",
      "85.45454545454545\n",
      "Enzo :\n",
      "8.401084010840108\n",
      "30.0\n",
      "Eva :\n",
      "8.93371757925072\n",
      "62.96296296296296\n",
      "Jarmo :\n",
      "12.063492063492063\n",
      "68.57142857142857\n",
      "Leon :\n",
      "3.602305475504323\n",
      "22.916666666666664\n",
      "Leonie :\n",
      "7.87037037037037\n",
      "8.0\n",
      "Noortje :\n",
      "7.707910750507099\n",
      "54.54545454545454\n",
      "Robin :\n",
      "6.122448979591836\n",
      "37.03703703703704\n",
      "Tirza :\n",
      "6.432748538011696\n",
      "57.49999999999999\n",
      "Tom :\n",
      "9.632224168126093\n",
      "43.42105263157895\n"
     ]
    }
   ],
   "source": [
    "# Run reproduction of tables\n",
    "run_reproduce_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stages\n",
    "- Stage 1: disyllables realized as monosyllabic\n",
    "- Stage 2: both syllables realized, but stress on first syllable\n",
    "- Stage 3: both syllables realized with equal stress\n",
    "- Stage 4: adult like stress realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a23cd0a18b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miamb_bisyl_phases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'FT'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miamb_bisyl_phases\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcalc_phase_1_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#['FT', 'FT', 'FT', 'FT', 'FT'], ['T', 'TF', 'TT', 'FT', 'AA'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-b5dbda882ac9>\u001b[0m in \u001b[0;36mcalc_phase_1_dev\u001b[0;34m(child, patterns)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_phase_1_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgoal_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_progress_of_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-9b00dac3a8c1>\u001b[0m in \u001b[0;36mcalculate_progress_of_patterns\u001b[0;34m(self, patterns)\u001b[0m\n\u001b[1;32m    138\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mreal_pat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatches_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_pat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# If realizations matches the corresponding real pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                                 \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_pat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TF'"
     ]
    }
   ],
   "source": [
    "iamb_bisyl_phases = ['T', 'TF', 'TT', 'FT', 'AA']\n",
    "patterns = {'FT': iamb_bisyl_phases}\n",
    "calc_phase_1_dev(leon, patterns)#['FT', 'FT', 'FT', 'FT', 'FT'], ['T', 'TF', 'TT', 'FT', 'AA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyternotebookvenv",
   "language": "python",
   "name": "jupyternotebookvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
